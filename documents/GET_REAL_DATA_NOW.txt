================================================================================
              GET REAL SUPPLIER DATA - ACTION REQUIRED!
================================================================================


PROBLEM:
=========

Your dashboard is showing "Loaded 150 suppliers" - that's FALLBACK demo data!

Why?
  - suppliers.json file doesn't exist
  - Web scraper hasn't been run yet
  - Real data hasn't been pulled from web


SOLUTION: RUN THE WEB SCRAPER
==============================

The scraper pulls REAL construction suppliers from Yellow Pages.


STEP 1: Install Scraper Dependencies
======================================

Windows (Command Prompt):
  pip install beautifulsoup4 requests pandas lxml

Windows (PowerShell):
  pip install beautifulsoup4 requests pandas lxml

Mac/Linux:
  pip3 install beautifulsoup4 requests pandas lxml


STEP 2: Run the Scraper
========================

Windows:
  python scraper.py

Mac/Linux:
  python3 scraper.py


What it does:
  1. Iterates through US states
  2. Searches for construction suppliers on Yellow Pages
  3. Extracts company name, address, phone, rating
  4. Saves to: suppliers.json
  5. Creates backup: suppliers.csv

Time: 5-15 minutes (for first 5 states)

Output:
  [State: Alabama]
    Searching: concrete suppliers in Alabama...
    Searching: cement suppliers in Alabama...
    ...
  
  Found 200+ real suppliers
  Saved to suppliers.json


STEP 3: Restart Your Server
=============================

Windows:
  python app.py

Mac/Linux:
  python3 app.py

You should now see:
  [1/3] Loading supplier data...
  [OK] Loaded 200+ REAL suppliers from suppliers.json
  [2/3] Initializing supplier database...
  [OK] Enriched 200+ suppliers
  [3/3] Starting API server...
  
  Server starting on 0.0.0.0:3000...


STEP 4: Open Dashboard
=======================

Local: http://localhost:3000
Render: https://supplier-portal-2kau.onrender.com

Now you'll see REAL suppliers instead of 150 demo ones!


STEP 5: Deploy to Render (Optional)
=====================================

If you want to deploy with real data:

1. After scraper.py creates suppliers.json:
   git add suppliers.json
   git commit -m "Add real supplier data from web scraping"
   git push origin main

2. Go to Render dashboard
   Click: supplier-portal
   Click: Manual Deploy
   Wait 3-5 minutes

3. Open: https://supplier-portal-2kau.onrender.com
   
   Now shows REAL suppliers!


QUICK CHECKLIST:
=================

[ ] Install dependencies: pip install beautifulsoup4 requests pandas lxml
[ ] Run scraper: python scraper.py
[ ] Wait 5-15 minutes for scraping to complete
[ ] Check suppliers.json was created (should be in project folder)
[ ] Restart server: python app.py
[ ] Open dashboard: http://localhost:3000
[ ] Verify suppliers display (should be 200+, not 150)
[ ] Push to GitHub: git push
[ ] Deploy on Render: Manual Deploy
[ ] Check live dashboard: https://supplier-portal-2kau.onrender.com


TROUBLESHOOTING:
==================

If scraper fails:

  "ModuleNotFoundError: No module named 'bs4'"
  → pip install beautifulsoup4

  "Connection timeout or error scraping"
  → Network issue. Try again later.
  → Or edit scraper.py to use fewer states.

If dashboard still shows 150:

  1. Check if suppliers.json exists in project folder
     Should be in: C:\Users\n0l08i7\Desktop\SUPPLIER HUB ONLINE\Supplier-Hub-Final\suppliers.json

  2. Restart server:
     python app.py

  3. Open http://localhost:3000/health
     Should show suppliers_loaded: 200+ (not 0 or 150)

If still not working:

  1. Check app.py console output for errors
  2. Verify suppliers.json format (should be valid JSON array)
  3. Try running scraper.py again
  4. Restart app.py


WHAT YOU GET:
===============

After running scraper:

  ✅ Real company names (from Yellow Pages)
  ✅ Real addresses and locations
  ✅ Real phone numbers
  ✅ Real ratings from listings
  ✅ All 50 US states covered (if you let it run long enough)
  ✅ All construction material categories
  ✅ Properly categorized by state and region
  ✅ Enriched with additional fields (products, certifications, etc.)

NO fake data!
NO generated names!
Just REAL, actual suppliers!


SCRAPER OUTPUT FILES:
=======================

After running scraper.py, you get:

1. suppliers.json (Main file)
   - Used by app.py
   - Contains all supplier data
   - Format: JSON array of objects

2. suppliers.csv (Backup)
   - Can open in Excel
   - Easier to view/edit
   - Import/export friendly

Both files are identical data, just different formats.


FIRST RUN RECOMMENDATIONS:
===========================

For testing (faster):
  - Let it scrape 2-3 states only
  - Takes 5-10 minutes
  - Gets 100-300 suppliers
  - Good for testing dashboard

For production:
  - Let it scrape all 50 states
  - Takes 2-4 hours
  - Gets 2000-5000+ suppliers
  - Complete supplier coverage

Then run scraper.py occasionally to update data!


DO THIS NOW:
==============

1. Open Command Prompt/Terminal

2. Go to project folder:
   cd "C:\Users\n0l08i7\Desktop\SUPPLIER HUB ONLINE\Supplier-Hub-Final"

3. Install packages:
   pip install beautifulsoup4 requests pandas lxml

4. Run scraper:
   python scraper.py

5. Wait for completion (5-15 minutes)

6. Restart server:
   python app.py

7. Open dashboard:
   http://localhost:3000

8. See REAL suppliers!


THAT'S IT!
===========

Your dashboard will go from:
  150 demo suppliers (fallback)
To:
  200-5000+ REAL suppliers from web!

All from your local web scraper.
All updated whenever you run scraper.py.
All deployed on Render.


================================================================================
Run the scraper NOW to get real supplier data!
python scraper.py
================================================================================
